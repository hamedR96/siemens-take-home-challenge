{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"hamedrahimi/Defect_Spectrum_cleaned\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T11:39:43.024126Z",
     "start_time": "2025-06-03T11:39:42.485042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import CLIPTokenizer\n",
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "\n",
    "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16)#,tokenizer=tokenizer,  torch_dtype=torch.bfloat16)\n",
    "pipe.enable_model_cpu_offload() #save some VRAM by offloading the model to CPU. Remove this if you have enough GPU power\n"
   ],
   "id": "6062ca4ce51adf3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24e2adc52a1440108ceedf7b99287b7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c4c30dcae234d1388fb41ca9c8438d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b06ec36b2b064eb1bb9ca4d0abac5f5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T11:40:39.763413Z",
     "start_time": "2025-06-03T11:40:39.725033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "prompt = \"A cat holding a sign that says hello world\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    #generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev.png\")\n"
   ],
   "id": "488e1c557f614ec6",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA cat holding a sign that says hello world\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mguidance_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_inference_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_sequence_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#generator=torch.Generator(\"cpu\").manual_seed(0)\u001B[39;49;00m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mimages[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     11\u001B[0m image\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflux-dev.png\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/Simens/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/Simens/lib/python3.10/site-packages/diffusers/pipelines/flux/pipeline_flux.py:810\u001B[0m, in \u001B[0;36mFluxPipeline.__call__\u001B[0;34m(self, prompt, prompt_2, negative_prompt, negative_prompt_2, true_cfg_scale, height, width, num_inference_steps, sigmas, guidance_scale, num_images_per_prompt, generator, latents, prompt_embeds, pooled_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, negative_ip_adapter_image, negative_ip_adapter_image_embeds, negative_prompt_embeds, negative_pooled_prompt_embeds, output_type, return_dict, joint_attention_kwargs, callback_on_step_end, callback_on_step_end_tensor_inputs, max_sequence_length)\u001B[0m\n\u001B[1;32m    802\u001B[0m has_neg_prompt \u001B[38;5;241m=\u001B[39m negative_prompt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m    803\u001B[0m     negative_prompt_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m negative_pooled_prompt_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    804\u001B[0m )\n\u001B[1;32m    805\u001B[0m do_true_cfg \u001B[38;5;241m=\u001B[39m true_cfg_scale \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_neg_prompt\n\u001B[1;32m    806\u001B[0m (\n\u001B[1;32m    807\u001B[0m     prompt_embeds,\n\u001B[1;32m    808\u001B[0m     pooled_prompt_embeds,\n\u001B[1;32m    809\u001B[0m     text_ids,\n\u001B[0;32m--> 810\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    811\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt_2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    813\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    814\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpooled_prompt_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpooled_prompt_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    815\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    816\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_images_per_prompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_images_per_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    817\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_sequence_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_sequence_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    818\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlora_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlora_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    819\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_true_cfg:\n\u001B[1;32m    821\u001B[0m     (\n\u001B[1;32m    822\u001B[0m         negative_prompt_embeds,\n\u001B[1;32m    823\u001B[0m         negative_pooled_prompt_embeds,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    833\u001B[0m         lora_scale\u001B[38;5;241m=\u001B[39mlora_scale,\n\u001B[1;32m    834\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/Simens/lib/python3.10/site-packages/diffusers/pipelines/flux/pipeline_flux.py:362\u001B[0m, in \u001B[0;36mFluxPipeline.encode_prompt\u001B[0;34m(self, prompt, prompt_2, device, num_images_per_prompt, prompt_embeds, pooled_prompt_embeds, max_sequence_length, lora_scale)\u001B[0m\n\u001B[1;32m    359\u001B[0m     prompt_2 \u001B[38;5;241m=\u001B[39m [prompt_2] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(prompt_2, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m prompt_2\n\u001B[1;32m    361\u001B[0m     \u001B[38;5;66;03m# We only use the pooled prompt output from the CLIPTextModel\u001B[39;00m\n\u001B[0;32m--> 362\u001B[0m     pooled_prompt_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_clip_prompt_embeds\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_images_per_prompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_images_per_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    367\u001B[0m     prompt_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_t5_prompt_embeds(\n\u001B[1;32m    368\u001B[0m         prompt\u001B[38;5;241m=\u001B[39mprompt_2,\n\u001B[1;32m    369\u001B[0m         num_images_per_prompt\u001B[38;5;241m=\u001B[39mnum_images_per_prompt,\n\u001B[1;32m    370\u001B[0m         max_sequence_length\u001B[38;5;241m=\u001B[39mmax_sequence_length,\n\u001B[1;32m    371\u001B[0m         device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[1;32m    372\u001B[0m     )\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_encoder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/Simens/lib/python3.10/site-packages/diffusers/pipelines/flux/pipeline_flux.py:298\u001B[0m, in \u001B[0;36mFluxPipeline._get_clip_prompt_embeds\u001B[0;34m(self, prompt, num_images_per_prompt, device)\u001B[0m\n\u001B[1;32m    293\u001B[0m     removed_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(untruncated_ids[:, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer_max_length \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m : \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    294\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m    295\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe following part of your input was truncated because CLIP can only handle sequences up to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    296\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer_max_length\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokens: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mremoved_text\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    297\u001B[0m     )\n\u001B[0;32m--> 298\u001B[0m prompt_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_encoder(\u001B[43mtext_input_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m, output_hidden_states\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    300\u001B[0m \u001B[38;5;66;03m# Use pooled output of CLIPTextModel\u001B[39;00m\n\u001B[1;32m    301\u001B[0m prompt_embeds \u001B[38;5;241m=\u001B[39m prompt_embeds\u001B[38;5;241m.\u001B[39mpooler_output\n",
      "File \u001B[0;32m~/miniconda3/envs/Simens/lib/python3.10/site-packages/torch/cuda/__init__.py:363\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    358\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    359\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    360\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    361\u001B[0m     )\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 363\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    366\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    367\u001B[0m     )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3c9646506b4cfc21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
